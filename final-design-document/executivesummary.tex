\section{Executive Summary}

All musicians know the frustration that comes with writer’s block. Whether the musician
is making music for personal enjoyment or to meet a deadline, completing a piece of music
seems to be the most difficult part of writing, even when the initial design is complete.

Our solution to musical writer’s block is a stand-alone, easy to use, portable MIDI
controller that can fill in melodic structures inputted by a user. Our concept relies heavily on
artificial intelligence and machine learning that is supported with a well-designed MIDI
controller and onboard processors. Since we do not expect any musician to be familiar with
computer or electrical engineering, our MIDI controller will have an onboard display and a user
interface similar to a Digital Audio Workstation (DAW) where the user can edit, playback, and
quantize their entries to ensure their exact musical intent before processing the melody.

Currently, we have technology that can process and continue audio through artificial
intelligence such as Jukebox AI, but this requires an understanding of computer science
that not all musicians would enjoy learning. The aim of this project, then, is to put all the
technical aspects of this human/computer collaboration on the computer side. Using Machine
Learning, we can train the computer to recognize music patterns and structures such that it
could generate a comprehensive melody at the press of a button.

This stand-alone controller should be able to operate to its fullest extent without
needing to connect to any external device and have an appropriate device battery for travel
and rehearsal. As a MIDI controller, it will have spring loaded keys, be able to sense key
velocity, and input note values as a generic MIDI input with the velocity, pitch, and channel
information embedded in the input. This keyboard should have 2 octaves of keys with a button
to allow the input to change octaves up and down.

The keys will be 3D printed using PET plastic from CAD models designed by the group.
The body will most likely be a combination of laser-cut wood and 3D printed parts. It will also
have a display and a user interface consisting of a few knobs, arrow keys, and buttons to be
used to interact with the display, which will be protected by a clear sheet of acrylic.

We aim to have a 6.35 mm audio jack output to playback the recorded MIDI values in
time, as well as provide a metronome count-in before recording. To record and process the
melody, the user interface will include “metronome settings, edit, and auto-complete” as well
as a play button, record, and pause button.

The ‘metronome settings’ will bring the user to a settings window where the current
‘beats per minute’ (BPM) is displayed and can be increased or decreased with the turn of a
knob, and selected with a button. The ‘metronome settings’ will also include a ‘time signature’
selection to prompt the metronome of the correct count-in. The ‘playback select’ will play the
recorded midi back through the input audio device. ‘Record’ will start the metronome count-in,
which will be displayed on-screen, and begin recording the key inputs to the DAW. ‘Edit’ will
open up another settings window which will allow the user to select the ‘quantize’ parameters
and apply the quantization. ‘Edit’ will also allow the user to select individual notes and move
them up or down the melodic range to correct any mistakes. And finally, ‘auto-complete’ will
communicate to the device that the user would like to send the MIDI information through the
[MYSTERIOUS BLACK BOX OF AI]™ and complete whatever melody had been inputted.

For our stretch goals, we would like to push the size of the keyboard to a 3-octave
keyboard. We would also like to add the additional option of ‘chord auto-complete’ where the
device will take the completed inputted melody and create a chord structure to support that
melody.

If possible, we would also like to include speakers to provide live feedback without
headphones. We would also like to attempt to add a sound library consisting of a few
synthesizers or other programmable sound fonts. We could also change the display to a touch
screen or cover the display in gorilla glass.

A greater application of this project is that it could also be used as a helpful device for
teaching melodic writing.

Bibliography reference example \autocite{adams1995hitchhiker}
